{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's execute the below cell to display information about the CUDA driver and GPUs running on the server by running the `nvidia-smi` command. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "The **goal** of this lab is to:\n",
    "- Learn about GPU occupancy, and  OpenACC vs CUDA execution model \n",
    "- Learn how to find out GPU occupancy from the Nsight Systems profiler\n",
    "- Learn how to improve the occupancy and saturate compute resources \n",
    "- Learn about collapse clauses for further optimization of the parallel nested loops and when to use them\n",
    "- Apply collapse clause to eligible nested loops in the application and investigate the profiler report\n",
    "\n",
    "We do not intend to cover:\n",
    "\n",
    "- OpenACC Programming models\n",
    "- Advanced Optimization techniques in detail\n",
    "\n",
    "Look at the profiler report from the previous exercise again. From the timeline, have a close look at the kernel functions. We can see that the for example `semi_discrete_steps_249_gpu` kernel has a theoretical  occupancy of 50% . It clearly shows that occupancy is a limiting factor. *Occupancy* is a measure of how well the GPU compute resources are being utilized. It is about how much parallelism is running / how much parallelism the hardware could run.\n",
    "\n",
    "<img src=\"images/occu-2_.png\" width=\"25%\" height=\"25%\">\n",
    "\n",
    "NVIDIA GPUs are comprised of multiple streaming multiprocessors (SMs) where it can manage up to 2048 concurrent threads (not actively running at the same time). Low occupancy shows that there are not enough active threads to fully utilize the computing resources. Higher occupancy implies that the scheduler has more active threads to choose from and hence achieves higher performance. So, what does this mean in OpenACC execution model?\n",
    "\n",
    "**Gang, Worker, and Vector**\n",
    "CUDA and OpenACC programming model use different terminologies for similar ideas. For example, in CUDA, parallel execution is organized into grids, blocks, and threads. On the other hand, the OpenACC execution model has three levels of gang, worker, and vector. OpenACC assumes the device has multiple processing elements (Streaming Multiprocessors on NVIDIA GPUs) running in parallel and the mapping of OpenACC execution model on CUDA is as below:\n",
    "\n",
    "- An OpenACC gang is a threadblock\n",
    "- A worker is a warp\n",
    "- An OpenACC vector is a CUDA thread\n",
    "\n",
    "<img src=\"images/diagram.png\" width=\"50%\" height=\"50%\">\n",
    "\n",
    "So, in order to improve the occupancy, we have to increase the parallelism within the gang. In other words, we have to increase the number of threads that can be scheduled on the GPU to improve GPU thread occupancy.\n",
    "\n",
    "**Optimizing loops and improving occupancy**\n",
    "Let's have a look at the compiler feedback (*Line 249*) and the corresponding code snippet showing three tightly nested loops (the lines in the compiler feedback might be slightly different for you). \n",
    "\n",
    "<img src=\"images/cfeedback2_.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "The iteration count for the outer loop is `NUM_VARS` which is 4. As you can see from the above screenshot, the block dimension is <1,1,1> which shows the small amount of parallelism within the gang.\n",
    "\n",
    "```cpp\n",
    "#pragma acc parallel loop private(indt, indf1, indf2) \n",
    "  for (ll = 0; ll < NUM_VARS; ll++)\n",
    "  {\n",
    "    for (k = 0; k < nz; k++)\n",
    "    {\n",
    "      for (i = 0; i < nx; i++)\n",
    "      {\n",
    "        indt = ll * nz * nx + k * nx + i;\n",
    "        indf1 = ll * (nz + 1) * (nx + 1) + k * (nx + 1) + i;\n",
    "        indf2 = ll * (nz + 1) * (nx + 1) + k * (nx + 1) + i + 1;\n",
    "        tend[indt] = -(flux[indf2] - flux[indf1]) / dx;\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```\n",
    "\n",
    "In order to expose more parallelism and improve the occupancy, we can use an additional clause called `collapse` in the `#pragma acc loop` to optimize loops. The loop directive gives the compiler additional information about the next loop in the source code through several clauses. Apply the `collapse(N)` clause to a loop directive to collapse the next `N` tightly-nested loops to be collapsed into a single, flattened loop. This is useful if you have many nested loops or when you have really short loops. \n",
    "\n",
    "When the loop count in any of some tightly nested loops is relatively small compared to the available number of threads in the device, creating a single iteration space across all the nested loops, increases the iteration count thus allowing the compiler to extract more parallelism.\n",
    "\n",
    "**Tips on where to use:**\n",
    "- Collapse outer loops to enable the creation of more gangs.\n",
    "- Collapse inner loops to enable longer vector lengths.\n",
    "- Collapse all loops, when possible, to do both\n",
    "\n",
    "We added the `collapse` clause to the code and made the necessary changes to the loop directives. Feel free to inspect the code <b>[miniWeather_openacc.cpp](../source_code/lab3/miniWeather_openacc.cpp)</b>. Let's compile the code, inspect the compiler feedback and profile it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../source_code/lab3 && make clean && make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us start inspecting the compiler feedback and see if it applied the optimizations (the lines in the compiler feedback might be slightly different for you). Here is the screenshot of expected compiler feedback after adding the `collapse`clause to the code. You can see that nested loops on lines 249 and 278 have been successfully collapsed.\n",
    "\n",
    "<img src=\"images/cfeedback3_.png\" width=\"80%\" height=\"80%\">\n",
    "\n",
    "Now, **Profile** the code with Nsight Systems command line `nsys`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../source_code/lab3 && nsys profile -t nvtx,openacc --stats=true --force-overwrite true -o miniWeather_3 ./miniWeather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and save the report file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](../source_code/lab3/miniWeather_3.nsys-rep) and choosing <mark>Save Link As</mark>. Once done open the report via the Nsight System UI  locally and have a close look at the kernel functions on the timeline and the occupancy.\n",
    "\n",
    "<img src=\"images/occu-3_.png\" width=\"70%\">\n",
    "\n",
    "As you can see from the above screenshot, the theoretical occupancy is now 75% and the block dimension is now `<128,1,1>` where *128* is the vector size per gang. **Screenshots represent profiler reports for the values of 400,200,200.**\n",
    "\n",
    "```cpp\n",
    "#pragma acc parallel loop collapse(3) private(inds, indt)\n",
    "  for (ll = 0; ll < NUM_VARS; ll++)\n",
    "  {\n",
    "    for (k = 0; k < nz; k++)\n",
    "    {\n",
    "      for (i = 0; i < nx; i++)\n",
    "      {\n",
    "        inds = ll * (nz + 2 * hs) * (nx + 2 * hs) + (k + hs) * (nx + 2 * hs) + i + hs;\n",
    "        indt = ll * nz * nx + k * nx + i;\n",
    "        state_out[inds] = state_init[inds] + dt * tend[indt];\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "The iteration count for the collapsed loop is `NUM_VARS * nz * nx` where (in the example screenshot),\n",
    "\n",
    "- nz= 200,\n",
    "- nx = 400, and \n",
    "- NUM_VARS = 4\n",
    "\n",
    "So, the iteration count for this particular loop inside the `semi_discrete_steps_249_gpu` function is 320K. This number divided by the vector length of *128* would give us the grid dimension of `<2500,1,1>`.\n",
    "\n",
    "By creating a single iteration space across the nested loops and increasing the iteration count, we improved the occupancy and extracted more parallelism.\n",
    "\n",
    "**Notes:**\n",
    "- 100% occupancy is not required, nor does it guarantee the best performance.\n",
    "- Less than 50% occupancy is often a red flag\n",
    "\n",
    "How much this optimization will speed-up the code will vary according to the application and the target accelerator, but it is not uncommon to see large speed-ups by using collapse on loop nests.\n",
    "\n",
    "Moreover, you can see that the `semi_discrete_steps_249_gpu` function now takes 3.9% compared to 50.1% from the previous section. This means the bottleneck shifted and now we have to focus on another kernel. In the next session, we focus on optimizing the data movement and reducing all the non-necessary data migrations. \n",
    "\n",
    "<img src=\"images/compare_23.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Lab Summary\n",
    "\n",
    "If you would like to download this lab for later viewing, it is recommend you go to your browsers File menu (not the Jupyter notebook file menu) and save the complete web page.  This will ensure the images are copied down as well. You can also execute the following cell block to create a zip-file of the files you've been working on, and download it with the link below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "rm -f _profiler_files.zip\n",
    "zip -r _profiler_files.zip *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After** executing the above zip command, you should be able to download and save the zip file by holding down <mark>Shift</mark> and <mark>Right-Clicking</mark> [Here](../_profiler_files.zip) and choosing <mark>Save Link As</mark>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# <p style=\"text-align:center; border:3px; border-style:solid; border-color:#FF0000  ; padding: 1em\"> <a href=../_start_profiling.ipynb>HOME</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style=\"float:center\"> <a href=profiling_lab4.ipynb>NEXT</a></span> </p>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links and Resources\n",
    "\n",
    "[OpenACC API Guide](https://www.openacc.org/sites/default/files/inline-files/OpenACC%20API%202.6%20Reference%20Guide.pdf)\n",
    "\n",
    "[NVIDIA Nsight System](https://docs.nvidia.com/nsight-systems/)\n",
    "\n",
    "[CUDA Toolkit Download](https://developer.nvidia.com/cuda-downloads)\n",
    "\n",
    "**NOTE**: To be able to see the Nsight System profiler output, please download Nsight System latest version from [here](https://developer.nvidia.com/nsight-systems).\n",
    "\n",
    "Don't forget to check out additional [OpenACC Resources](https://www.openacc.org/resources) and join our [OpenACC Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "--- \n",
    "\n",
    "## Licensing \n",
    "\n",
    "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
