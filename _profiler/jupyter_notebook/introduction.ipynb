{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin, let's execute the below cell to display information about the CUDA driver and GPUs running on the server by running the `nvidia-smi` command. To do this, execute the cell block below by giving it focus (clicking on it with your mouse), and hitting Ctrl-Enter, or pressing the play button in the toolbar above. If all goes well, you should see some output returned below the grey cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives\n",
    "The **goal** of this lab is to:\n",
    "\n",
    "- Learn how to profile your application using NVIDIA profiling tools\n",
    "- Learn and understand the Nsight systems and compute profiler report\n",
    "- Learn how to integrate NVTX markers in your application to trace CPU events when profiling \n",
    "- Learn about the optimziation cycle and how to find bottleneck via the NVIDIA profiling tools\n",
    "\n",
    "We do not intend to cover:\n",
    "\n",
    "- OpenACC programming model and optimization techniques in detail\n",
    "\n",
    "# NVIDIA Profiler\n",
    "\n",
    "### What is profiling\n",
    "Profiling is the first step in optimizing and tuning your application. Profiling an application would help us understand where most of the execution time is spent. You will gain an understanding of its performance characteristics and can easily identify parts of the code that present opportunities for improvement. Finding hotspots and bottlenecks in your application can help you decide where to focus your optimization efforts.\n",
    "\n",
    "### NVIDIA Nsight Tools\n",
    "NVIDIA offers Nsight tools (Nsight Systems, Nsight Compute, Nsight Graphics), a collection of applications which enable developers to debug, profile the performance of CUDA, OpenACC, or OpenMP applications. \n",
    "\n",
    "Your profiling workflow will change to reflect the individual Nsight tools. Start with Nsight Systems to get a system-level overview of the workload and eliminate any system-level bottlenecks, such as unnecessary thread synchronization or data movement, and improve the system-level parallelism of your algorithms. Once you have done that, proceed to Nsight Compute or Nsight Graphics to optimize the most significant CUDA kernels or graphics workloads. Periodically return to Nsight Systems to ensure that you remain focused on the largest bottleneck. Otherwise, the bottleneck may have shifted and your kernel level optimizations may not achieve as high of an improvement as expected.\n",
    "\n",
    "- **Nsight Systems** analyze application algorithm system-wide\n",
    "- **Nsight Compute** debug and optimize CUDA kernels \n",
    "- **Nsight Graphics** debug and optimize graphic workloads\n",
    "\n",
    "<img src=\"images/Nsight Diagram.png\" width=\"80%\" height=\"80%\">\n",
    "*The data flow between the NVIDIA Nsight tools.*\n",
    "\n",
    "**Please follow the links to learn more about [Nsight Systems](nsight_systems.ipynb) and [Nsight Compute](nsight_compute.ipynb) (links contain notebooks)**. Once you reviewed the content, follow the below sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to follow\n",
    "<a name=\"steps\"></a>\n",
    "\n",
    "To obtain the best performance from GPU and utilize the hardware, one should follow the cyclical process (analyze, parallelize, optimize). \n",
    "\n",
    "- **Analyze**: In this step, you first identify the portion of your code that includes most of the computation and most of the execution time is spent. From here, you find the hotspots, evaluate the bottlenecks, and investigate GPU acceleration.\n",
    "\n",
    "- **Parallelize**: Now that we have identified the bottlenecks, we use the techniques to paralellise the routines where most of the time is spent.\n",
    "\n",
    "- **Optimize**:  To further improve the performance, one can implement optimization strategies step by step in an iterative process including: identify optimization opportunities, apply and test the optimization method, verify and repeat the process.\n",
    "\n",
    "Note: The above optimization is done incrementally after investigating the profiler output.\n",
    "\n",
    "We will follow the optimization cycle for porting and improving the code performance.\n",
    "\n",
    "<img src=\"images/Optimization_Cycle.jpg\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started \n",
    "In the following sections, we parallelise and optimize the serial [mini weather application](miniweather.ipynb) following the above steps. Next section comprises 5 exercises, each will guide you through steps to detect performance limiters and steps to overcome them. For each exercise, inspect the code, compile, and profile it. Then, investigate the profilerâ€™s report to identify the bottlenecks and spot the optimization opportunities.  At each step, locate problem areas in the application and make improvements iteratively to increase performance.\n",
    "\n",
    "This lab comprises multiple exercises, each following the optimization cycle method. For each exercise, build the code by running the `make` and profile. In these labs, we focus on Nsight Systems to get the system-wide actionable insights to eliminate bottlenecks as well as deep diving into the kernel using Nsight Compute.\n",
    "\n",
    "\n",
    "**NOTE**: Example screenshots are for reference only and you may not get an identical profiler report. In other words, some **screenshots represent profiler reports for the values of 400,200,1500. Throughout the notebook, we change these values/parameters to reduce the runtime.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# <div style=\"text-align: center ;border:3px; border-style:solid; border-color:#FF0000  ; padding: 1em\">[NEXT](profiling_lab1.ipynb)</div>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Links and Resources\n",
    "\n",
    "\n",
    "[NVIDIA Nsight System](https://docs.nvidia.com/nsight-systems/)\n",
    "\n",
    "\n",
    "**NOTE**: To be able to see the Nsight System profiler output, please download Nsight System's latest version from [here](https://developer.nvidia.com/nsight-systems).\n",
    "\n",
    "Don't forget to check out additional [OpenACC Resources](https://www.openacc.org/resources) and join our [OpenACC Slack Channel](https://www.openacc.org/community#slack) to share your experience and get more help from the community.\n",
    "\n",
    "--- \n",
    "\n",
    "## Licensing \n",
    "\n",
    "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
